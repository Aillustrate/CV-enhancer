{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "019380b8-3635-4c07-9078-8f689004977a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9b64ebd5-c723-4c66-9dcb-7bfec9255c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'LLMmatch'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Enumerating objects: 40, done.\u001b[K\n",
      "remote: Counting objects: 100% (40/40), done.\u001b[K\n",
      "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
      "remote: Total 40 (delta 18), reused 37 (delta 18), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (40/40), 585.05 KiB | 2.42 MiB/s, done.\n",
      "Resolving deltas: 100% (18/18), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/abdullinilgiz/LLMmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e99b79d-c7fb-4241-8dfd-eb42d45ce260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/eugene/Documents/CV-enhancement/LLMmatch\n",
      "Already up to date.\n",
      "/home/eugene/Documents/CV-enhancement\n"
     ]
    }
   ],
   "source": [
    "%cd LLMmatch\n",
    "!git pull\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f48beb5-ee86-4606-af48-f79f0e1825b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1d452da-13a2-49cd-9b6a-1889193b72da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/home/eugene/Documents/CV-enhancement/src/utils.py'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import utils\n",
    "\n",
    "reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18a376cd-27ef-4092-a8b6-31d688fef13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import save_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5cc7aefc-8802-4e15-a188-6a73f32a1e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = [\n",
    "    job.replace(\".txt\", \"\")\n",
    "    for job in os.listdir(\"LLMmatch/data/matches\")\n",
    "    if job.endswith(\".txt\")\n",
    "]\n",
    "for job in jobs:\n",
    "    save_matches(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca938b2b-7c0d-4502-b878-f90b42f9c331",
   "metadata": {},
   "source": [
    "# Загрузка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2d8cc87-5276-4f4c-a9cf-f475bde9e0ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7e49d7f12824042900f14e74b6cff15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# MODEL_NAME = 'meta-llama/Llama-2-7b-chat-hf'\n",
    "MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME, torch_dtype=torch.float16, low_cpu_mem_usage=True\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "model.to(\"cuda\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c475269-2a4d-4d2c-8056-6000e6928114",
   "metadata": {},
   "source": [
    "# Пайплайн"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abbe137c-f5c5-4895-a377-cbefeefdbd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import logging\n",
    "import random\n",
    "import string\n",
    "\n",
    "\n",
    "def make_id():\n",
    "    chars = list(string.ascii_lowercase) + list(map(str, list(range(0, 9)) * 5))\n",
    "    return \"\".join(random.sample(chars, 6))\n",
    "\n",
    "\n",
    "class CVEnhancer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        tokenizer,\n",
    "        system_prompt_path=\"prompts/system_prompt.txt\",\n",
    "        user_prompt_path=\"prompts/user_prompt.txt\",\n",
    "        report_path=\"evaluation/report.json\",\n",
    "        max_len=100000,\n",
    "    ):\n",
    "        self.ASSISTANT_MESSAGE_START = \"\\nAssistant:Hello! As a career assiatant, I am glad to help you. I will give you a detailed review of your CV and give some advice to help you improve it so that it will fit the job better.\"\n",
    "        self.RESPONSE_REGEXP = self.__get_response_regexp()\n",
    "        self.TEMPLATE = \"<s>[INST] <<SYS>> {system_prompt} <</SYS>> {user_message} [/INST]{assistant_message}\"\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        with open(system_prompt_path) as f:\n",
    "            self.system_prompt = f.read()\n",
    "        with open(user_prompt_path) as f:\n",
    "            self.user_prompt = f.read()\n",
    "        self.report_path = report_path\n",
    "        self.logger = logger = logging.getLogger()\n",
    "        self.logger.setLevel(logging.INFO)\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __get_response_regexp(self):\n",
    "        assistant_message_start_regexp = self.ASSISTANT_MESSAGE_START.replace(\n",
    "            \"\\n\", \"\"\n",
    "        ).replace(\".\", \"\\.\")\n",
    "        text_regexp = \"[\\S\\s]*\"\n",
    "        return re.compile(f\"(?<={assistant_message_start_regexp}){text_regexp}\")\n",
    "\n",
    "    def make_prompt(self, cv_path, job_path):\n",
    "        with open(cv_path) as f:\n",
    "            cv = f.read()\n",
    "        with open(job_path) as f:\n",
    "            job = f.read()\n",
    "        user_prompt = self.user_prompt.format(cv=cv, job=job)\n",
    "        return self.TEMPLATE.format(\n",
    "            system_prompt=self.system_prompt,\n",
    "            user_message=user_prompt,\n",
    "            assistant_message=self.ASSISTANT_MESSAGE_START,\n",
    "        )\n",
    "\n",
    "    def generate_text(self, text, **generation_kwargs):\n",
    "        input_ids = self.tokenizer(text, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "        output = self.tokenizer.decode(\n",
    "            self.model.generate(\n",
    "                input_ids,\n",
    "                pad_token_id=self.tokenizer.eos_token_id,\n",
    "                max_new_tokens=self.max_len,\n",
    "                **generation_kwargs,\n",
    "            )[0]\n",
    "        )\n",
    "        return output\n",
    "\n",
    "    def process(self, llm_output):\n",
    "        llm_output = llm_output.replace(\"</s>\", \"\")\n",
    "        return llm_output\n",
    "\n",
    "    def extract(self, llm_output):\n",
    "        llm_output = self.process(llm_output)\n",
    "        matches = self.RESPONSE_REGEXP.findall(llm_output)\n",
    "        if matches:\n",
    "            return matches[0].lstrip()\n",
    "        return \"\"\n",
    "\n",
    "    def save_report(self, llm_output, cv_path, job_path, **generation_kwargs):\n",
    "        reports = load_or_create_json(self.report_path)\n",
    "        new_report = {\n",
    "            \"cv\": cv_path,\n",
    "            \"job\": job_path,\n",
    "            \"system_prompt\": self.system_prompt,\n",
    "            **generation_kwargs,\n",
    "            \"model\": MODEL_NAME,\n",
    "            \"output\": llm_output,\n",
    "        }\n",
    "        report_id = make_id()\n",
    "        reports.update({report_id: new_report})\n",
    "        with open(self.report_path, \"w\") as jf:\n",
    "            json.dump(reports, jf)\n",
    "        # logging.info(f'Report saved to {self.report_path}')\n",
    "\n",
    "    def enhance(self, cv_path, job_path, save_report=True, **generation_kwargs):\n",
    "        prompt = self.make_prompt(cv_path, job_path)\n",
    "        llm_output = self.generate_text(prompt, **generation_kwargs)\n",
    "        llm_output = self.extract(llm_output)\n",
    "        if save_report:\n",
    "            self.save_report(llm_output, cv_path, job_path, **generation_kwargs)\n",
    "        return llm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "264e9a80-63dc-4cca-9493-5f50cd018760",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.enhancer import CVEnhancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "755ed4b2-437f-49d8-adce-6432d3375c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First, let's take a look at how well your CV matches the job description.\n",
      "\n",
      "The job description is looking for a System Analyst with 3-6 years of experience. However, your CV shows that you have only 4 years and 11 months of experience. This means that you may not be the most suitable candidate for this job.\n",
      "\n",
      "In addition, the job description requires experience in IT-related development, but your CV does not mention any experience in this area. This means that you may need to acquire some relevant skills and experience in order to apply for this job.\n",
      "\n",
      "Now, let's take a closer look at your CV and see what can be improved.\n",
      "\n",
      "Work Experience:\n",
      "\n",
      "Your CV shows that you have 4 years and 11 months of experience as a System Analyst. This is a good start, but it would be helpful to provide more specific details about your experience. For example, you could mention any specific projects you have worked on, any challenges you faced, and how you overcame them.\n",
      "\n",
      "You could also highlight any skills or technologies that you have experience with, such as Java/Kotlin, Spring Boot, PostgreSQL, Apache Kafka, openshift/k8s, TypeScript, React, React Native, etc.\n",
      "\n",
      "Education:\n",
      "\n",
      "Your CV shows that you have a degree in Applied Mathematics and Computer Science from the Moscow State University of Technology. This is a good start, but it would be helpful to mention any specific courses or areas of study that are relevant to the job you are applying for.\n",
      "\n",
      "For example, if the job requires experience with Java/Kotlin, you could mention any courses you have taken in this area. If the job requires experience with Spring Boot, you could mention any courses or projects you have worked on using this technology.\n",
      "\n",
      "Hard and Soft Skills:\n",
      "\n",
      "Your CV shows that you have experience in systems analysis, but it does not mention any specific skills or technologies that you have experience with. This means that you may need to acquire some relevant skills and experience in order to apply for this job.\n",
      "\n",
      "For example, if the job requires experience with Java/Kotlin, you could mention any specific skills or technologies you have experience with in this area. If the job requires experience with Spring Boot, you could mention any specific skills or technologies you have experience with in this area.\n",
      "\n",
      "In addition, it would be helpful to mention any soft skills that you have, such as communication, teamwork, problem-solving, etc. These skills are important for any job, and they can help you stand out from other candidates.\n",
      "\n",
      "If you are not sure what skills or technologies are relevant for the job you are applying for, I would recommend doing some research on the company and the position. You can also ask the employer if they have any specific requirements or recommendations for the job.\n",
      "\n",
      "If you are not sure how to acquire the necessary skills or experience, I would recommend looking into online courses or training programs. There are many resources available online that can help you learn new skills and gain experience in your field.\n",
      "\n",
      "In conclusion, while your CV shows some relevant experience and education, it may not be the best match for the job you are applying for. In order to improve your chances of getting the job, I would recommend acquiring some relevant skills and experience, and highlighting these in your CV. Good luck with your job search!\n"
     ]
    }
   ],
   "source": [
    "enhancer = CVEnhancer(model, tokenizer, MODEL_NAME)\n",
    "generation_kwargs = {\"do_sample\": False, \"temperature\": 1}\n",
    "print(\n",
    "    enhancer.enhance(\n",
    "        cv_path=\"data/CVs/sys_analitic.txt\",\n",
    "        job_path=\"data/Vacancies/sys_analitic/1.txt\",\n",
    "        save_report=True,\n",
    "        **generation_kwargs\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07241dbf-f3bc-4993-bbb0-efc81cf3f4b8",
   "metadata": {},
   "source": [
    "# Эксперименты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4afd4752-4424-4402-8a81-eee40329db26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "def cleanup():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "def experiment(enhancer, jobs, temperatures=(1.0, 1.25, 1.5, 1.75, 2.0)):\n",
    "    generation_kwargs_combinations = [{\"do_sample\": False, \"temperature\": 1.0}]\n",
    "    for t in temperatures:\n",
    "        generation_kwargs_combinations.append({\"do_sample\": True, \"temperature\": t})\n",
    "\n",
    "    with tqdm(total=len(generation_kwargs_combinations) * len(jobs)) as pbar:\n",
    "        for generation_kwargs in generation_kwargs_combinations:\n",
    "            for job in jobs:\n",
    "                cv_path = os.path.join(\"data\", \"CVs\", f\"{job}.txt\")\n",
    "                vacancy_dir = os.path.join(\"data\", \"Vacancies\", job)\n",
    "                for vacancy in (\n",
    "                    f for f in os.listdir(vacancy_dir) if f.endswith(\".txt\")\n",
    "                ):\n",
    "                    vacancy_path = os.path.join(vacancy_dir, vacancy)\n",
    "                    pbar.set_description(f\"{vacancy_path} {generation_kwargs}\")\n",
    "                    enhancer.enhance(\n",
    "                        cv_path, vacancy_path, save_report=True, **generation_kwargs\n",
    "                    )\n",
    "                    cleanup()\n",
    "                pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "690b110f-ae3f-4536-9453-a256a4a98a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a2870ce-b70b-4a83-8783-4a630a293009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0659447e2a484e6195f2b9fba40475bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eugene/miniconda3/envs/myenv/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:386: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (4096). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n"
     ]
    }
   ],
   "source": [
    "enhancer = CVEnhancer(model, tokenizer, max_len=1000)\n",
    "jobs = [\n",
    "    job.replace(\".txt\", \"\")\n",
    "    for job in os.listdir(\"LLMmatch/data/matches\")\n",
    "    if job.endswith(\".txt\")\n",
    "]\n",
    "temperatures = (1.0, 1.25, 1.5, 1.75, 2.0)\n",
    "experiment(enhancer, jobs, temperatures=(1.0, 1.25, 1.5, 1.75, 2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bafbbd-ec30-4daa-8360-e465835c1af2",
   "metadata": {},
   "source": [
    "# Оценка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e5d8087-7324-406b-b915-0aab80d5bb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "class Evaluator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        report_path=\"evaluation/report.json\",\n",
    "        eval_dir=\"evaluation/results\",\n",
    "        guidelines_path=\"evaluation/guidelines.json\",\n",
    "        urls_path=\"evaluation/urls.json\",\n",
    "        shuffle=True,\n",
    "    ):\n",
    "        self.annotator = input(\"Enter your name\")\n",
    "        self.report_path = report_path\n",
    "        self.eval_path = os.path.join(eval_dir, f\"{self.annotator}_eval.json\")\n",
    "        self.reports = self.load(self.report_path)\n",
    "        self.evaluated = self.load(self.eval_path)\n",
    "        self.CRITERIA = {\n",
    "            \"adequacy\": (0, 5),\n",
    "            \"reliability\": (0, 5),\n",
    "            \"usefulness\": (0, 5),\n",
    "            \"honesty\": (0, 5),\n",
    "            \"linguistic correctness\": (0, 5),\n",
    "            \"coherence\": (0, 5),\n",
    "        }\n",
    "        with open(guidelines_path) as jf:\n",
    "            self.guidelines = json.load(jf)\n",
    "        with open(urls_path) as jf:\n",
    "            self.urls = json.load(jf)\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def load(self, path):\n",
    "        if os.path.exists(path):\n",
    "            with open(path) as jf:\n",
    "                return json.load(jf)\n",
    "        return {}\n",
    "\n",
    "    def evaluate_report(self, report_id):\n",
    "        report = self.reports[report_id]\n",
    "        clear_output()\n",
    "\n",
    "        print(f\"CV: {report['cv']}\\nVacancy:{report['job']}\\n\")\n",
    "\n",
    "        guideline = self.guidelines.get(f\"{report['cv']} & {report['job']}\", \"\")\n",
    "        cv_url = self.urls.get(report[\"cv\"])\n",
    "        vacancy_url = self.urls.get(report[\"job\"])\n",
    "        if cv_url:\n",
    "            print(f\"CV URL: {cv_url}\")\n",
    "        if vacancy_url:\n",
    "            print(f\"VACANCY URL: {vacancy_url}\")\n",
    "\n",
    "        if guideline:\n",
    "            print(f\"guidelines: {guideline}\\n\")\n",
    "\n",
    "        print(report[\"output\"])\n",
    "\n",
    "        scores = {}\n",
    "        for criterion, (min_score, max_score) in self.CRITERIA.items():\n",
    "            score = int(input(f\"{criterion} ({min_score}-{max_score})\"))\n",
    "            scores.update({criterion: score})\n",
    "        self.evaluated.update({report_id: {**report, **scores}})\n",
    "        with open(self.eval_path, \"w\") as jf:\n",
    "            json.dump(self.evaluated, jf)\n",
    "\n",
    "    def run(self):\n",
    "        report_ids = list(self.reports.keys())\n",
    "        if self.shuffle:\n",
    "            random.shuffle(report_ids)\n",
    "        for report_id in report_ids:\n",
    "            if not report_id in self.evaluated:\n",
    "                self.evaluate_report(report_id)\n",
    "        print(\"All texts were evaluated. Thank you!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1ff99498-3248-4475-a1c0-2cbf5716f903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV: data/CVs/electro.txt\n",
      "Vacancy:data/Vacancies/electro/1.txt\n",
      "\n",
      "VACANCY URL: (https://novosibirsk.hh.ru/vacancy/89244253?from=vacancy_search_list&hhtmFrom=vacancy_search_list&query=%D0%BA%D0%B0%D0%B1%D0%B5%D0%BB%D1%8C%D1%89%D0%B8%D0%BA)\n",
      "guidelines: Оценка 8/10: Нет группы допуска V\n",
      "\n",
      "CV Analysis:\n",
      "1. Experience: This section of your CV shows your background in the field of cable connections, electronics and maintenance of telecommunication systems. Based on the information provided, it seems that you have more than 4 years of relevant experience in your field, specifically working as a \"Кабельщик-спайщик\" for at least two different employers, \"МГТС\"  Moscow Global Information Technologies & Systematics  and \"Спецстрой России\" which indicates a strong potential background that will match well with the job description.\n",
      "2. Job Description: The job you have your sights set on, that of an electronically skilled network technician, primarily concerns with installations, masonry works and electrical works. Given your expertise in network electronics this job would require further studies such as an IT courses to have more solid knowledge in the latest technology.\n",
      "3. Hiring Manager’s Expectations: Based on the information in your CV and the skills and tasks required on this job, to be considered a relevant experience we would recommend to also present any IT certifications you hold or obtain ones in future to complete your qualification level for this kind of positions. As you would require to work mainly outside office hours which might include weekends and holidays in order to have greater efficiency during the network construction and maintenance in the construction sites.\n",
      "4. Company and Position Match: The jobs listed on the job description as possible positions to apply are in telecommunication company which is very suited your profile since all of the companies that require the position also have positions which suit to a huge part of your background of experience. Some specific skills like work outside of office times and dealing with dangerous conditions and hazards in sites like you have experience with is well suited, but you need to make sure they are emphasised in you CV before submitting it.\n",
      "5. Education related to the job: You could improve your CV by including the specific IT courses, if that is possible on the company’s site, that you took with relation to networking and data. You may find more courses you will do useful and can list in the future.\n",
      "6. Qualifications such as a driver's license/ certification or a certification program: Not mentioned. I recommend you to look if relevant classes in the areas like network architecture that are suited the most for you can be taken soon. You may still look into professional license such as Routing, TCP IP networking.\n",
      "7. References, if needed: Include them. \n",
      "\n",
      "As a person with extensive experience, as an assistant professional,  the ideal job for you should be a \"Канализато́пный электравлаг\", also known as a \"Maintenance engineer, electrical distribution systems\" for you. This career choice will use the most of your expertise to be hired in Moscow or its satellite area where a new project of creating submersed fiber optic networks is starting as the project will require cable work in construction work zones, which allows you to bring your work experience in laying cables on land  to a next level of development because it has to work with equipment while using techniques needed at these sites to achieve a network connection result.\n",
      "\n",
      "Considerations before applying for a job \n",
      "Before considering submitting your CV be sure do some research: 1) Research the market for cable networks engineering positions, this will give you insight in the company offers, job post requirements for your qualifications: if job position you aspired for required some certification but you don’t have one, check to where it fits in network engineering spectrum and decide if you need one and see how longer you would need to get the certification. 2) Take time to\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mEvaluator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 67\u001b[0m, in \u001b[0;36mEvaluator.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m report_id \u001b[38;5;129;01min\u001b[39;00m report_ids:\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m report_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluated:\n\u001b[0;32m---> 67\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreport_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAll texts were evaluated. Thank you!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[11], line 54\u001b[0m, in \u001b[0;36mEvaluator.evaluate_report\u001b[0;34m(self, report_id)\u001b[0m\n\u001b[1;32m     52\u001b[0m scores \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m criterion, (min_score, max_score) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mCRITERIA\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 54\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcriterion\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m (\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmin_score\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmax_score\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     55\u001b[0m     scores\u001b[38;5;241m.\u001b[39mupdate({criterion:score})\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluated\u001b[38;5;241m.\u001b[39mupdate({report_id: {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mreport, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscores}})\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/ipykernel/kernelbase.py:1175\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_stdin:\n\u001b[1;32m   1172\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(\n\u001b[1;32m   1173\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1174\u001b[0m     )\n\u001b[0;32m-> 1175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/ipykernel/kernelbase.py:1217\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1216\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m   1218\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "Evaluator().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "721c32e1-67d5-4a67-9250-e24df19c6add",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def aggregate_evaluations(eval_dir=\"evaluation/results\"):\n",
    "    criteria = [\n",
    "        \"adequacy\",\n",
    "        \"reliability\",\n",
    "        \"usefulness\",\n",
    "        \"honesty\",\n",
    "        \"linguistic correctness\",\n",
    "        \"coherence\",\n",
    "    ]\n",
    "    agg_criteria = {criterion: \"mean\" for criterion in criteria}\n",
    "    all_evals = []\n",
    "    fnames = [fname for fname in os.listdir(eval_dir) if fname.endswith(\".json\")]\n",
    "    for i, fname in enumerate(fnames):\n",
    "        path = os.path.join(eval_dir, fname)\n",
    "        with open(path) as jf:\n",
    "            evals = json.load(jf)\n",
    "        for report_id, report in evals.items():\n",
    "            eval = {\"id\": report_id, \"annotator\": i, **report}\n",
    "            all_evals.append(eval)\n",
    "    return (\n",
    "        pd.DataFrame(all_evals)\n",
    "        .groupby([\"model\", \"do_sample\", \"temperature\"])\n",
    "        .agg({\"id\": \"count\", **agg_criteria})\n",
    "        .round(2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "600c2bad-a89e-4558-bb93-93faa88dc02f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_7d705_row0_col1, #T_7d705_row0_col3, #T_7d705_row0_col4, #T_7d705_row0_col5, #T_7d705_row1_col5, #T_7d705_row2_col0, #T_7d705_row2_col2, #T_7d705_row2_col4, #T_7d705_row2_col5, #T_7d705_row5_col0, #T_7d705_row6_col2, #T_7d705_row6_col5, #T_7d705_row7_col4, #T_7d705_row7_col5, #T_7d705_row7_col6 {\n",
       "  background-color: green;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_7d705\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7d705_level0_col0\" class=\"col_heading level0 col0\" >id</th>\n",
       "      <th id=\"T_7d705_level0_col1\" class=\"col_heading level0 col1\" >adequacy</th>\n",
       "      <th id=\"T_7d705_level0_col2\" class=\"col_heading level0 col2\" >reliability</th>\n",
       "      <th id=\"T_7d705_level0_col3\" class=\"col_heading level0 col3\" >usefulness</th>\n",
       "      <th id=\"T_7d705_level0_col4\" class=\"col_heading level0 col4\" >honesty</th>\n",
       "      <th id=\"T_7d705_level0_col5\" class=\"col_heading level0 col5\" >linguistic correctness</th>\n",
       "      <th id=\"T_7d705_level0_col6\" class=\"col_heading level0 col6\" >coherence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >model</th>\n",
       "      <th class=\"index_name level1\" >do_sample</th>\n",
       "      <th class=\"index_name level2\" >temperature</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7d705_level0_row0\" class=\"row_heading level0 row0\" rowspan=\"6\">meta-llama/Llama-2-7b-chat-hf</th>\n",
       "      <th id=\"T_7d705_level1_row0\" class=\"row_heading level1 row0\" >False</th>\n",
       "      <th id=\"T_7d705_level2_row0\" class=\"row_heading level2 row0\" >1.000000</th>\n",
       "      <td id=\"T_7d705_row0_col0\" class=\"data row0 col0\" >4</td>\n",
       "      <td id=\"T_7d705_row0_col1\" class=\"data row0 col1\" >4.750000</td>\n",
       "      <td id=\"T_7d705_row0_col2\" class=\"data row0 col2\" >4.250000</td>\n",
       "      <td id=\"T_7d705_row0_col3\" class=\"data row0 col3\" >4.500000</td>\n",
       "      <td id=\"T_7d705_row0_col4\" class=\"data row0 col4\" >5.000000</td>\n",
       "      <td id=\"T_7d705_row0_col5\" class=\"data row0 col5\" >5.000000</td>\n",
       "      <td id=\"T_7d705_row0_col6\" class=\"data row0 col6\" >4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7d705_level1_row1\" class=\"row_heading level1 row1\" rowspan=\"5\">True</th>\n",
       "      <th id=\"T_7d705_level2_row1\" class=\"row_heading level2 row1\" >1.000000</th>\n",
       "      <td id=\"T_7d705_row1_col0\" class=\"data row1 col0\" >4</td>\n",
       "      <td id=\"T_7d705_row1_col1\" class=\"data row1 col1\" >3.750000</td>\n",
       "      <td id=\"T_7d705_row1_col2\" class=\"data row1 col2\" >3.500000</td>\n",
       "      <td id=\"T_7d705_row1_col3\" class=\"data row1 col3\" >4.000000</td>\n",
       "      <td id=\"T_7d705_row1_col4\" class=\"data row1 col4\" >4.250000</td>\n",
       "      <td id=\"T_7d705_row1_col5\" class=\"data row1 col5\" >5.000000</td>\n",
       "      <td id=\"T_7d705_row1_col6\" class=\"data row1 col6\" >4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7d705_level2_row2\" class=\"row_heading level2 row2\" >1.250000</th>\n",
       "      <td id=\"T_7d705_row2_col0\" class=\"data row2 col0\" >6</td>\n",
       "      <td id=\"T_7d705_row2_col1\" class=\"data row2 col1\" >2.830000</td>\n",
       "      <td id=\"T_7d705_row2_col2\" class=\"data row2 col2\" >4.330000</td>\n",
       "      <td id=\"T_7d705_row2_col3\" class=\"data row2 col3\" >2.500000</td>\n",
       "      <td id=\"T_7d705_row2_col4\" class=\"data row2 col4\" >5.000000</td>\n",
       "      <td id=\"T_7d705_row2_col5\" class=\"data row2 col5\" >5.000000</td>\n",
       "      <td id=\"T_7d705_row2_col6\" class=\"data row2 col6\" >4.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7d705_level2_row3\" class=\"row_heading level2 row3\" >1.500000</th>\n",
       "      <td id=\"T_7d705_row3_col0\" class=\"data row3 col0\" >4</td>\n",
       "      <td id=\"T_7d705_row3_col1\" class=\"data row3 col1\" >2.750000</td>\n",
       "      <td id=\"T_7d705_row3_col2\" class=\"data row3 col2\" >2.750000</td>\n",
       "      <td id=\"T_7d705_row3_col3\" class=\"data row3 col3\" >3.250000</td>\n",
       "      <td id=\"T_7d705_row3_col4\" class=\"data row3 col4\" >3.750000</td>\n",
       "      <td id=\"T_7d705_row3_col5\" class=\"data row3 col5\" >3.000000</td>\n",
       "      <td id=\"T_7d705_row3_col6\" class=\"data row3 col6\" >3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7d705_level2_row4\" class=\"row_heading level2 row4\" >1.750000</th>\n",
       "      <td id=\"T_7d705_row4_col0\" class=\"data row4 col0\" >4</td>\n",
       "      <td id=\"T_7d705_row4_col1\" class=\"data row4 col1\" >3.250000</td>\n",
       "      <td id=\"T_7d705_row4_col2\" class=\"data row4 col2\" >3.500000</td>\n",
       "      <td id=\"T_7d705_row4_col3\" class=\"data row4 col3\" >3.750000</td>\n",
       "      <td id=\"T_7d705_row4_col4\" class=\"data row4 col4\" >4.000000</td>\n",
       "      <td id=\"T_7d705_row4_col5\" class=\"data row4 col5\" >3.250000</td>\n",
       "      <td id=\"T_7d705_row4_col6\" class=\"data row4 col6\" >2.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7d705_level2_row5\" class=\"row_heading level2 row5\" >2.000000</th>\n",
       "      <td id=\"T_7d705_row5_col0\" class=\"data row5 col0\" >6</td>\n",
       "      <td id=\"T_7d705_row5_col1\" class=\"data row5 col1\" >2.500000</td>\n",
       "      <td id=\"T_7d705_row5_col2\" class=\"data row5 col2\" >2.330000</td>\n",
       "      <td id=\"T_7d705_row5_col3\" class=\"data row5 col3\" >2.500000</td>\n",
       "      <td id=\"T_7d705_row5_col4\" class=\"data row5 col4\" >3.170000</td>\n",
       "      <td id=\"T_7d705_row5_col5\" class=\"data row5 col5\" >2.170000</td>\n",
       "      <td id=\"T_7d705_row5_col6\" class=\"data row5 col6\" >1.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7d705_level0_row6\" class=\"row_heading level0 row6\" rowspan=\"6\">mistralai/Mistral-7B-Instruct-v0.1</th>\n",
       "      <th id=\"T_7d705_level1_row6\" class=\"row_heading level1 row6\" >False</th>\n",
       "      <th id=\"T_7d705_level2_row6\" class=\"row_heading level2 row6\" >1.000000</th>\n",
       "      <td id=\"T_7d705_row6_col0\" class=\"data row6 col0\" >3</td>\n",
       "      <td id=\"T_7d705_row6_col1\" class=\"data row6 col1\" >3.670000</td>\n",
       "      <td id=\"T_7d705_row6_col2\" class=\"data row6 col2\" >4.330000</td>\n",
       "      <td id=\"T_7d705_row6_col3\" class=\"data row6 col3\" >3.330000</td>\n",
       "      <td id=\"T_7d705_row6_col4\" class=\"data row6 col4\" >4.670000</td>\n",
       "      <td id=\"T_7d705_row6_col5\" class=\"data row6 col5\" >5.000000</td>\n",
       "      <td id=\"T_7d705_row6_col6\" class=\"data row6 col6\" >4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7d705_level1_row7\" class=\"row_heading level1 row7\" rowspan=\"5\">True</th>\n",
       "      <th id=\"T_7d705_level2_row7\" class=\"row_heading level2 row7\" >1.000000</th>\n",
       "      <td id=\"T_7d705_row7_col0\" class=\"data row7 col0\" >2</td>\n",
       "      <td id=\"T_7d705_row7_col1\" class=\"data row7 col1\" >3.500000</td>\n",
       "      <td id=\"T_7d705_row7_col2\" class=\"data row7 col2\" >4.000000</td>\n",
       "      <td id=\"T_7d705_row7_col3\" class=\"data row7 col3\" >4.000000</td>\n",
       "      <td id=\"T_7d705_row7_col4\" class=\"data row7 col4\" >5.000000</td>\n",
       "      <td id=\"T_7d705_row7_col5\" class=\"data row7 col5\" >5.000000</td>\n",
       "      <td id=\"T_7d705_row7_col6\" class=\"data row7 col6\" >5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7d705_level2_row8\" class=\"row_heading level2 row8\" >1.250000</th>\n",
       "      <td id=\"T_7d705_row8_col0\" class=\"data row8 col0\" >1</td>\n",
       "      <td id=\"T_7d705_row8_col1\" class=\"data row8 col1\" >0.000000</td>\n",
       "      <td id=\"T_7d705_row8_col2\" class=\"data row8 col2\" >0.000000</td>\n",
       "      <td id=\"T_7d705_row8_col3\" class=\"data row8 col3\" >0.000000</td>\n",
       "      <td id=\"T_7d705_row8_col4\" class=\"data row8 col4\" >0.000000</td>\n",
       "      <td id=\"T_7d705_row8_col5\" class=\"data row8 col5\" >0.000000</td>\n",
       "      <td id=\"T_7d705_row8_col6\" class=\"data row8 col6\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7d705_level2_row9\" class=\"row_heading level2 row9\" >1.500000</th>\n",
       "      <td id=\"T_7d705_row9_col0\" class=\"data row9 col0\" >3</td>\n",
       "      <td id=\"T_7d705_row9_col1\" class=\"data row9 col1\" >1.670000</td>\n",
       "      <td id=\"T_7d705_row9_col2\" class=\"data row9 col2\" >1.330000</td>\n",
       "      <td id=\"T_7d705_row9_col3\" class=\"data row9 col3\" >1.670000</td>\n",
       "      <td id=\"T_7d705_row9_col4\" class=\"data row9 col4\" >2.000000</td>\n",
       "      <td id=\"T_7d705_row9_col5\" class=\"data row9 col5\" >3.000000</td>\n",
       "      <td id=\"T_7d705_row9_col6\" class=\"data row9 col6\" >2.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7d705_level2_row10\" class=\"row_heading level2 row10\" >1.750000</th>\n",
       "      <td id=\"T_7d705_row10_col0\" class=\"data row10 col0\" >3</td>\n",
       "      <td id=\"T_7d705_row10_col1\" class=\"data row10 col1\" >1.000000</td>\n",
       "      <td id=\"T_7d705_row10_col2\" class=\"data row10 col2\" >0.000000</td>\n",
       "      <td id=\"T_7d705_row10_col3\" class=\"data row10 col3\" >0.000000</td>\n",
       "      <td id=\"T_7d705_row10_col4\" class=\"data row10 col4\" >0.000000</td>\n",
       "      <td id=\"T_7d705_row10_col5\" class=\"data row10 col5\" >1.670000</td>\n",
       "      <td id=\"T_7d705_row10_col6\" class=\"data row10 col6\" >1.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7d705_level2_row11\" class=\"row_heading level2 row11\" >2.000000</th>\n",
       "      <td id=\"T_7d705_row11_col0\" class=\"data row11 col0\" >4</td>\n",
       "      <td id=\"T_7d705_row11_col1\" class=\"data row11 col1\" >0.000000</td>\n",
       "      <td id=\"T_7d705_row11_col2\" class=\"data row11 col2\" >2.000000</td>\n",
       "      <td id=\"T_7d705_row11_col3\" class=\"data row11 col3\" >0.250000</td>\n",
       "      <td id=\"T_7d705_row11_col4\" class=\"data row11 col4\" >2.000000</td>\n",
       "      <td id=\"T_7d705_row11_col5\" class=\"data row11 col5\" >1.750000</td>\n",
       "      <td id=\"T_7d705_row11_col6\" class=\"data row11 col6\" >0.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f16ec293f40>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = aggregate_evaluations()\n",
    "results.style.highlight_max(color=\"green\", axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1750e96c-b319-445a-a087-7bca0e7c6a2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
